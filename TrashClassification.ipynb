{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b166168-de9c-4535-a061-b9d7b6209bf5",
   "metadata": {},
   "source": [
    "1._________________ Setup and load the data___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f253cb-3a0f-4039-a974-b457fcc0f543",
   "metadata": {},
   "source": [
    "1.1 Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce1829-5a84-4dd1-bb8f-f84cdd4856d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5a88f5-be48-4afd-bbe3-7b7c794711ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os  \n",
    "from tensorflow import keras\n",
    "import cv2 \n",
    "import imghdr \n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import Precision, Recall, Accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eeb3cd-dc71-4fbe-9721-62882e7c8330",
   "metadata": {},
   "source": [
    "1.2 Remove dodgy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a455dc2-eb67-4dd5-9710-752f0b206f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "image_exts = ['jpeg','jpg', 'png']\n",
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image) \n",
    "        try: \n",
    "            img = cv2.imread(image_path) \n",
    "            tip = imghdr.what(image_path)  \n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path) \n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88233ae8-cd9b-4e05-96dd-eb9f6f2f63f3",
   "metadata": {},
   "source": [
    "1.3 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95de56-fa76-401f-88eb-7bc44fbaaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data',image_size=(128, 128))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70c1e7-78e7-4de5-84a1-f89f00bcded3",
   "metadata": {},
   "source": [
    "2. Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b6bc3-aabd-4f8e-b6ca-b19eb1074f18",
   "metadata": {},
   "source": [
    "2.1 Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4102b-73f1-447b-ba99-0c4c986e9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64881e18-3e68-45f7-b2db-ff1fe79881ea",
   "metadata": {},
   "source": [
    "2.2 Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950ffee-9641-4f4a-929b-49add280f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.75)\n",
    "val_size = int(len(data)*0.2)\n",
    "test_size = int(len(data)*0.05)\n",
    "train = data.take(train_size) \n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05ca65-cf91-43c0-b878-08b763cd3c44",
   "metadata": {},
   "source": [
    "3. DEEP MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145968c7-a7b7-406e-a45c-b8f648f75f4b",
   "metadata": {},
   "source": [
    "3.1 Built deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afc80e-5340-439c-94b0-4b8afca7bd47",
   "metadata": {},
   "source": [
    "3.1.1 CNN basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f7e34-eb60-46a7-8a12-f484b2b5fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu', input_shape=(128,128,3))) \n",
    "model.add(MaxPooling2D(2,2)) \n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da40e5-51a2-4bed-bc0a-443c3d150a2e",
   "metadata": {},
   "source": [
    "3.1.2 CNN basic model regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69ae16-2bcb-4a82-91f4-5a0b15d56d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu', input_shape=(128,128,3))) \n",
    "model.add(MaxPooling2D(2,2)) \n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer = tf.keras.regularizers.l2(0.05)))\n",
    "model.add(Dense(6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c3bf5-6fdd-4828-bae6-1a932d40b475",
   "metadata": {},
   "source": [
    "3.1.3 CNN basic model regularized Fine-tuning (this part must be run after the fist training of the model 3.1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af26a61-c6db-4b18-a4d2-867d338b6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 4  \n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ca09e-f2c3-4d4f-b730-81861affe585",
   "metadata": {},
   "source": [
    "3.1.4 Alternative model (Pre-trained model VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3ed38-52bc-4647-a79e-bfc96d7ea17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, \n",
    "                                         input_shape=(128, 128, 3))\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100  \n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a30b9-9d75-4a8b-95d8-069ca1686554",
   "metadata": {},
   "source": [
    "3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305dfb3-bb24-4325-8bb2-472bbc72ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "hist = model.fit(train, epochs=15, validation_data=val, callbacks=[tensorboard_callback])\n",
    "model.summary()\n",
    "logdir='logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(train, epochs=5, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cefde9-e588-471d-8f7b-7153209b2698",
   "metadata": {},
   "source": [
    "3.3 Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfd827-a515-4f5e-9046-da2bb7001619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083c4c5-08ec-4631-ab04-530722adb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac906f8-7ce9-43a0-bf60-7a03e093c374",
   "metadata": {},
   "source": [
    "4. Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034992b-8851-4d91-84db-8497bbc14fa3",
   "metadata": {},
   "source": [
    "4.1 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe24da-4510-4054-bf5b-d3b9b70f98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = Accuracy()\n",
    "y1=[]\n",
    "y_true =[]\n",
    "y_pred = [] \n",
    "l=0\n",
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    l=l+1\n",
    "    if l==test_size:\n",
    "        for i in range(32):\n",
    "            y1.append(yhat[i].argmax())\n",
    "            y_true.append(y[i])\n",
    "            y_pred.append(yhat[i].argmax())\n",
    "    else:\n",
    "        for i in range(32):\n",
    "            y1.append(yhat[i].argmax())\n",
    "            y_true.append(y[i])\n",
    "            y_pred.append(yhat[i].argmax())\n",
    "            \n",
    "    pre.update_state(y, y1)\n",
    "    re.update_state(y, y1)\n",
    "    acc.update_state(y, y1)\n",
    "    y1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad59bb-9722-48ea-b3ef-f81e766ccee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"presition: {pre.result().numpy()}, recall: {re.result().numpy()}, accuracy: {acc.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6919d-2144-47df-ad1e-eb88d4f9b354",
   "metadata": {},
   "source": [
    "4.1.1 Confution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec27895-b428-435c-8c29-0c8208bc9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.transpose(y_true), np.transpose(y_pred))\n",
    "classes = ['carton', 'vidrio', 'plastico', 'papel', 'metal', 'basura comun']\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.xlabel('Predicción')\n",
    "\n",
    "# Graficar la matriz de confusión\n",
    "plot_confusion_matrix(cm, classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec80308-d520-4e9b-9ef6-9812fc6d16a7",
   "metadata": {},
   "source": [
    "4.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83be858-5b4d-43f4-bfdd-cc1815fb8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('carton.jpg')\n",
    "plt.imshow(img)\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "resize = tf.image.resize(img, (128,128))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "yhat.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bac072-9438-4592-be78-c309c132d721",
   "metadata": {},
   "source": [
    "5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df0787-92ed-4421-b632-d56a25d43db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','ImageTrashClassification.h5'))\n",
    "new_model = load_model(os.path.join('models','ImageTrashClassification.h5'))\n",
    "yhat=new_model.predict(np.expand_dims(resize/255, 0))\n",
    "yhat.argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrashCassification",
   "language": "python",
   "name": "trashcassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
